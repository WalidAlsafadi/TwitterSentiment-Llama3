{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pictures/Twitter-Sentiment-Analysis.png](Pictures/Twitter-Sentiment-Analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:dodgerBlue; font-weight:bold;'> Twitter Sentiment Analysis </span>\n",
    "\n",
    "### <span style='color:aqua; font-weight:bold;'> Project Context: </span>\n",
    "\n",
    "In this project, we aim to explore the sentiments and opinions of people in Gaza, as expressed on social media, specifically Twitter. The focus is to gather real-time tweets, process and clean the data, and perform sentiment analysis. The insights gained can help better understand the prevailing mood, attitudes, and general discourse around specific topics related to Gaza, including social, political, and humanitarian issues.\n",
    "\n",
    "<b>The project involves the use of the following technologies:</b>\n",
    "\n",
    "* **Twitter Scraping**: Selenium is used to scrape real-time tweets, targeting specific hashtags and topics, due to limitations with paid APIs.\n",
    "* **Data Cleaning**: Python is employed to clean the scraped data by removing unwanted symbols, URLs, and filtering the text.\n",
    "* **Sentiment Analysis and LLM Integration**: Groq’s LLM, particularly the llama3-70b-8192 model, is integrated to conduct sentiment analysis and provide real-time question-answering capabilities on the collected tweets, enabling a deeper understanding of the data.\n",
    "\n",
    "The goal is to provide meaningful insights into the feelings and reactions of individuals in Gaza based on public social media posts, which could support researchers, humanitarian organizations, and policymakers in understanding the sentiment landscape.\n",
    "\n",
    "<b>Key Components:</b>\n",
    "\n",
    "1. **Data Collection**: Tweets are scraped using Selenium, focusing on specific hashtags and topics.\n",
    "2. **Data Cleaning**: Removing unwanted symbols, URLs, and filtering English texts to ensure clean and usable data.\n",
    "3. **Sentiment Analysis & LLM Integration**: Using Groq’s LLM to perform sentiment analysis and answer questions about the data simultaneously.\n",
    "4. **Insights**: The resulting sentiment analysis provides critical insights into public opinions, which could support researchers and humanitarian organizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:aqua; font-weight:bold;'> Import Packages </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Web Scraping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Text Preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# LLM\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:dodgerblue; font-weight:bold;'>Web Scraping</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Why Selenium?</b>\n",
    "\n",
    "Selenium is a powerful tool for web scraping dynamic content, especially when data is loaded through JavaScript and cannot be accessed through static HTML alone. In my project, Twitter’s dynamic page content requires interaction with a live webpage, making Selenium ideal for automating the browser to extract tweets directly. It allows for flexible handling of infinite scroll and JavaScript-rendered content, which other scraping tools might miss.\n",
    "\n",
    "<b>Note:</b> Make sure that your google chrome and chromedriver are at the same versions to avoid errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:aqua; font-weight:bold;'> Set up WebDriver </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read credentials from a text file\n",
    "with open('credentials.txt', 'r') as file:\n",
    "    credentials = file.readlines()\n",
    "    username = credentials[0].strip()\n",
    "    password = credentials[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your ChromeDriver\n",
    "driver_path = 'C:\\\\Users\\\\ppc\\\\Desktop\\\\chromedriver-win64\\\\chromedriver.exe'  # path to chromedriver\n",
    "login_url = 'https://x.com/login'\n",
    "# Chose a term to search (english tweet only)\n",
    "search_term = 'gaza'\n",
    "encoded_search_term = search_term.replace(' ', '%20').replace('#', '%23')\n",
    "search_url = f'https://x.com/search?f=top&q={encoded_search_term}%20({encoded_search_term})%20lang%3Aen&src=typed_query'\n",
    "\n",
    "# Set up the WebDriver\n",
    "service = Service(driver_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open the Twitter login page\n",
    "driver.get(login_url)\n",
    "time.sleep(5)  # Give it time to load\n",
    "\n",
    "# Locate the username and password input fields\n",
    "username_input = driver.find_element(By.NAME, \"text\")\n",
    "username_input.send_keys(username)\n",
    "username_input.send_keys(Keys.RETURN)  # Press Enter after typing the username\n",
    "\n",
    "time.sleep(5)  # Wait for password page to load\n",
    "\n",
    "# Locate the password input field\n",
    "password_input = driver.find_element(By.NAME, \"password\")\n",
    "password_input.send_keys(password)\n",
    "password_input.send_keys(Keys.RETURN)  # Press Enter after typing the password\n",
    "\n",
    "# Wait for login to complete\n",
    "time.sleep(5)\n",
    "\n",
    "# Navigate to the search page\n",
    "driver.get(search_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:aqua; font-weight:bold;'> Scraping tweets </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the page time to load\n",
    "time.sleep(20)\n",
    "\n",
    "# Define a function to scrape tweets\n",
    "def get_tweets():\n",
    "    tweets = driver.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')\n",
    "    return [tweet.text for tweet in tweets]\n",
    "\n",
    "# Limit for the number of tweets to collect\n",
    "tweet_limit = 25\n",
    "tweets = []\n",
    "\n",
    "# Keep track of attempts when no new tweets are loaded\n",
    "max_stagnation_attempts = 5\n",
    "stagnation_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 5 tweets so far...\n",
      "Collected 5 tweets so far...\n",
      "Collected 5 tweets so far...\n",
      "Collected 5 tweets so far...\n",
      "Collected 5 tweets so far...\n",
      "Collected 8 tweets so far...\n",
      "Collected 15 tweets so far...\n",
      "Collected 20 tweets so far...\n",
      "Collected 20 tweets so far...\n",
      "Collected 20 tweets so far...\n",
      "Collected 20 tweets so far...\n",
      "Collected 20 tweets so far...\n",
      "Collected 20 tweets so far...\n",
      "#BREAKING An Israeli military helicopter crashed in Rafah, Gaza last night; reportedly resulting in the deaths of three Israeli personnel and injuries to eight others.\n",
      "22-year-old Amit Levi was murdered by Hamas at the Nova Music Festival on October 7th.\n",
      "\n",
      "Her twin sister Shani, who was by her side in her last moments, survived the attack.\n",
      "\n",
      "Just a reminder in case people start forgetting why the IDF is in the Gaza Strip\n",
      "Will followers of Allah appreciate this dance for Gaza?\n",
      "They were peacefully sleeping in their tents, now their bodies disappeared into the sand. \n",
      "\n",
      "lsraeli warplanes target a tent camp to the west of Khan Yunis with five missiles, killing and tearing apart more than 40 displaced Palestinians. \n",
      "\n",
      "More than 20 tents, along with who were\n",
      "They could be your parents. \n",
      "\n",
      "Your siblings. \n",
      "\n",
      "Your boyfriend or girlfriend. \n",
      "\n",
      "Your best friend. \n",
      "\n",
      "These are just some of the 101 Israelis being held hostage in Gaza. \n",
      "\n",
      "Don’t look away.\n",
      "America Actress/Singer Zendaya has used her massive following to help raise money for the children of Gaza…\n",
      "\n",
      "Palestine children relief fund has raised a staggering $30,682,812 in humanitarian aid for the victims in Gaza..\n",
      "I celebrated my birthday in the perfect place, orphans camp! And with perfect people,Ele Elna Elak team!\n",
      "\n",
      "This team is working daily, tirelessly and without hesitation to serve the people of Gaza Strip in these conditions!,\n",
      "\n",
      "CALL TO ACTION:\n",
      "Make sure to visit the link in my bio\n",
      "Children of Gaza vs Children of Israel\n",
      "\n",
      "Do you see the difference?\n",
      "TURKEY EXPOSED\n",
      "\n",
      "Turkey just threatened to invade Israel, to stop them from attacking Gaza.\n",
      "\n",
      "However, in reality, Turkey has been sending oil to Israel for months.\n",
      "\n",
      "In this thread, I'll expose Turkey's Hypocrisy:\n",
      "\n",
      "(\n",
      "WATCH \n",
      "\n",
      "UNRWA terror school has just been erased in eastern Gaza\n",
      "This was Gaza before the war\n",
      "Netanyahu:\n",
      "\n",
      "Accusing me of war crimes in Gaza is like accusing George Bush of 9/11.\n",
      "Eden Yerushalmi was held captive in Gaza for nearly 11 months and was executed by Hamas.\n",
      "\n",
      "Her body, which was brought back to Israel, weighed only 36 kilos (79 pounds).\n",
      "\n",
      "Imagine the starvation and torture she was subjected to by her captors.\n",
      "\n",
      "Monsters.\n",
      "Since the Gaza war, the conversion rate of people accepting Islam has increased by 400% in Europe.\n",
      "Remember Ismail Al-Ghoul? He was the Al Jazeera \"journalist\" eliminated last Wednesday\n",
      "Guess what?\n",
      "He was a Hamas terrorist who took part in the October 7th massacre\n",
      "\n",
      "IDF Revealed a document from 2021, found on Hamas computers seized in the Gaza Strip, which details a list of\n",
      "I condemn in the strongest possible terms the assassination of Ismail Haniyeh, the Political Bureau Chairman of the Hamas resistance movement. \n",
      "\n",
      "This was a murder of the most heinous kind, plainly designed to derail ongoing talks aimed at ending the carnage in Gaza that has\n",
      "Harris, after the meeting with Netanyahu: \"We cannot continue to ignore the suffering in Gaza. I will not remain silent.\"\n",
      "\n",
      "The suffering in Gaza is not Israel's fault, dummy. Hamas is still alive and holds hostages. You're pathetic.\n",
      "\n",
      "Why anyone would vote for her is beyond me.\n",
      "China chose a design inspired by the Palestinian flag for the Paris 2024 Olympic Games.\n",
      "NEVER FORGET WHEN JUSTIN BIEBER POSTED PRAY FOR ISRAEL WHILST SHOWING A PICTURE OF DESTROYED GAZA\n",
      "Mega thread, #October7massacre - graphic \n",
      "Hello my enemies and all beautiful souls out there that are so concerned about casualties in Gaza - I promise to care once again if I find space in my brain when it finally processes this. Probably never. Educate urself >>\n"
     ]
    }
   ],
   "source": [
    "# Infinite scrolling and scraping loop\n",
    "while len(tweets) < tweet_limit and stagnation_count < max_stagnation_attempts:\n",
    "    # Scroll to the bottom of the page\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "    # Wait for new tweets to load\n",
    "    time.sleep(3)  # You can increase this if the internet connection is slow\n",
    "\n",
    "    # Get the new set of tweets after scrolling\n",
    "    new_tweets = get_tweets()\n",
    "    \n",
    "    # Append only unique tweets to avoid duplicates\n",
    "    initial_tweet_count = len(tweets)\n",
    "    \n",
    "    for tweet in new_tweets:\n",
    "        if tweet not in tweets:\n",
    "            tweets.append(tweet)\n",
    "        if len(tweets) >= tweet_limit:\n",
    "            break  # Exit the loop if we reach the tweet limit\n",
    "\n",
    "    # Check if new tweets were added\n",
    "    if len(tweets) > initial_tweet_count:\n",
    "        stagnation_count = 0  # Reset stagnation count if new tweets are found\n",
    "    else:\n",
    "        stagnation_count += 1  # Increment stagnation count if no new tweets are loaded\n",
    "    \n",
    "    print(f\"Collected {len(tweets)} tweets so far...\")\n",
    "\n",
    "# Print all gathered tweets\n",
    "for tweet in tweets:\n",
    "    print(tweet)\n",
    "\n",
    "# Close the browser when done\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:dodgerblue; font-weight:bold;'>Text Cleaning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the tweets to remove unnecessary elements like URLs, mentions, hashtags, and other noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    \"\"\"\n",
    "    Clean a tweet by removing URLs, mentions, hashtags, special characters, numbers,\n",
    "    and punctuation. Converts text to lowercase, removes stop words, and applies stemming.\n",
    "    \"\"\"\n",
    "    # Initialize stopwords and stemmer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    # Remove mentions and hashtags\n",
    "    tweet = re.sub(r'@\\w+|#\\w+', '', tweet)\n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    tweet = re.sub(r'[^A-Za-z\\s]+', '', tweet)\n",
    "    # Convert to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # Remove stop words\n",
    "    tweet_tokens = tweet.split()\n",
    "    tweet = ' '.join([word for word in tweet_tokens if word not in stop_words])\n",
    "    # Apply stemming\n",
    "    tweet = ' '.join([stemmer.stem(word) for word in tweet.split()])\n",
    "    # Remove extra spaces\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet).strip()\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arabic Version of **clean_tweet** Function\n",
    "\n",
    "**Note:** I'm not going to use this function in my case, because I scraped English tweets only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "\n",
    "def clean_arabic_tweet(tweet):\n",
    "    '''\n",
    "    Clean an Arabic tweet by removing URLs, mentions, hashtags, special characters, numbers,\n",
    "    and punctuation. Converts text to lowercase, removes Arabic stop words, and applies stemming.\n",
    "    '''\n",
    "    # Initialize Arabic stopwords and stemmer\n",
    "    arabic_stop_words = set(stopwords.words('arabic'))\n",
    "    stemmer = ISRIStemmer()\n",
    "    \n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    # Remove mentions and hashtags\n",
    "    tweet = re.sub(r'@\\w+|#\\w+', '', tweet)\n",
    "    # Remove non-Arabic characters, numbers, and punctuation\n",
    "    tweet = re.sub(r'[^\\u0600-\\u06FF\\s]+', '', tweet)  # This keeps only Arabic letters\n",
    "    # Remove extra spaces\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet).strip()\n",
    "    \n",
    "    # Split the tweet into tokens\n",
    "    tweet_tokens = tweet.split()\n",
    "    \n",
    "    # Remove Arabic stop words\n",
    "    tweet = ' '.join([word for word in tweet_tokens if word not in arabic_stop_words])\n",
    "    \n",
    "    # Apply stemming\n",
    "    tweet = ' '.join([stemmer.stem(word) for word in tweet.split()])\n",
    "    \n",
    "    return tweet\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isra militari helicopt crash rafah gaza last night reportedli result death three isra personnel injuri eight other\n",
      "yearold amit levi murder hama nova music festiv octob th twin sister shani side last moment surviv attack remind case peopl start forget idf gaza strip\n",
      "follow allah appreci danc gaza\n",
      "peac sleep tent bodi disappear sand lsraeli warplan target tent camp west khan yuni five missil kill tear apart displac palestinian tent along\n",
      "could parent sibl boyfriend girlfriend best friend isra held hostag gaza dont look away\n",
      "america actresssing zendaya use massiv follow help rais money children gaza palestin children relief fund rais stagger humanitarian aid victim gaza\n",
      "celebr birthday perfect place orphan camp perfect peopleel elna elak team team work daili tirelessli without hesit serv peopl gaza strip condit call action make sure visit link bio\n",
      "children gaza vs children israel see differ\n",
      "turkey expos turkey threaten invad israel stop attack gaza howev realiti turkey send oil israel month thread ill expos turkey hypocrisi\n",
      "watch unrwa terror school eras eastern gaza\n",
      "gaza war\n",
      "netanyahu accus war crime gaza like accus georg bush\n",
      "eden yerushalmi held captiv gaza nearli month execut hama bodi brought back israel weigh kilo pound imagin starvat tortur subject captor monster\n",
      "sinc gaza war convers rate peopl accept islam increas europ\n",
      "rememb ismail alghoul al jazeera journalist elimin last wednesday guess hama terrorist took part octob th massacr idf reveal document found hama comput seiz gaza strip detail list\n",
      "condemn strongest possibl term assassin ismail haniyeh polit bureau chairman hama resist movement murder heinou kind plainli design derail ongo talk aim end carnag gaza\n",
      "harri meet netanyahu cannot continu ignor suffer gaza remain silent suffer gaza israel fault dummi hama still aliv hold hostag your pathet anyon would vote beyond\n",
      "china chose design inspir palestinian flag pari olymp game\n",
      "never forget justin bieber post pray israel whilst show pictur destroy gaza\n",
      "mega thread graphic hello enemi beauti soul concern casualti gaza promis care find space brain final process probabl never educ urself\n"
     ]
    }
   ],
   "source": [
    "# Clean your collected tweets\n",
    "cleaned_tweets = [clean_tweet(tweet) for tweet in tweets]\n",
    "\n",
    "# Print cleaned tweets\n",
    "for tweet in cleaned_tweets:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:aqua; font-weight:bold;'> Save the DataFrame to a CSV file </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned tweets into a DataFrame\n",
    "df = pd.DataFrame(cleaned_tweets, columns=[\"tweet\"])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('cleaned_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:dodgerblue; font-weight:bold;'>Sentiment Analysis</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we used the **GroqCloud Llama-3 LLM (Large Language Model)** to perform sentiment analysis on the tweets we scraped and cleaned in previous steps. By leveraging the LLM, we aimed to gain deeper insights into how people feel about the situation in Gaza based on their tweets.\n",
    "\n",
    "We passed the cleaned tweets to the model and asked it to analyze the emotional tone and sentiment of the text. The model then provided a breakdown of various emotions (e.g.,fear, sadness, anger, hope) and categorized the tweets into **negative**, **neutral**, and **positive** sentiments.\n",
    "\n",
    "This method helped us extract valuable insights into how individuals are reacting emotionally to the current situation, with the model summarizing overall sentiments and key themes.\n",
    "\n",
    "**Note:** You can get your API Key from [Groq Website](https://groq.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After analyzing the tweets, I can provide some insights into the sentiment and feelings of the people of Gaza:\n",
      "\n",
      "**Overwhelming sense of fear and concern**: Many tweets express fear, concern, and empathy for the people of Gaza, highlighting the devastating effects of war, displacement, and humanitarian crises.\n",
      "\n",
      "**Anger and frustration**: There is a strong sense of anger and frustration towards the Israeli government and military, with many tweets accusing them of war crimes, human rights violations, and brutality.\n",
      "\n",
      "**Sense of injustice and oppression**: Tweets express a sense of injustice and oppression, with many feeling that the international community is not doing enough to stop the violence and protect Palestinian civilians.\n",
      "\n",
      "**Grief and mourning**: There are several tweets that express grief and mourning for the victims of violence, including children and civilians, and pay tribute to those who have lost their lives.\n",
      "\n",
      "**Solidarity and support**: Many tweets offer support and solidarity to the people of Gaza, with some calling for fundraising efforts, humanitarian aid, and political action to end the conflict.\n",
      "\n",
      "**Desperation and hopelessness**: Some tweets convey a sense of desperation and hopelessness, with feelings of being trapped, displaced, and subject to violence and intimidation.\n",
      "\n",
      "**Resilience and defiance**: Amidst the darkness, some tweets also express resilience and defiance, with people in Gaza and their supporters refusing to give up hope and continuing to advocate for their rights and freedom.\n",
      "\n",
      "**International attention and criticism**: The tweets suggest that there is a growing international movement criticizing Israel's actions in Gaza and calling for accountability, with some tweets highlighting the hypocrisy of some countries that claim to support human rights but fail to act.\n",
      "\n",
      "**Religious and political tensions**: The tweets also reveal religious and political tensions, with some tweets highlighting the role of Hamas and the Israeli government in the conflict, and others expressing concerns about the growing influence of extremist groups.\n",
      "\n",
      "**Humanization of the conflict**: Many tweets humanize the conflict, sharing personal stories, images, and videos that put a face to the statistics and highlight the human cost of the war.\n",
      "\n",
      "Overall, the sentiment of the people of Gaza and their supporters on Twitter is one of fear, anger, and frustration, but also of resilience, solidarity, and hope. The tweets call for an end to the violence, accountability for war crimes, and a lasting solution to the conflict that respects the rights and dignity of all parties involved."
     ]
    }
   ],
   "source": [
    "# Initialize the client with your API key\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "# Combine cleaned tweets into a single string\n",
    "tweets_text = \"\\n\".join(cleaned_tweets)\n",
    "\n",
    "# Construct a prompt for the LLM\n",
    "prompt = f\"\"\"Here are some recent tweets about Gaza:\n",
    "{tweets_text}\n",
    "\n",
    "Based on the tweets, how do the people of Gaza feel right now? Please perform a sentiment analysis and provide insights.\"\"\"\n",
    "\n",
    "# Send the prompt to the LLM for sentiment analysis\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama3-70b-8192\",  # I have used llama3-70b model, there is another models as well.\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None,\n",
    ")\n",
    "\n",
    "# Print the output from the LLM\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:dodgerblue; font-weight:bold;'>Project Overview</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary goal of this project is to collect and analyze tweets related to Gaza, using natural language processing (NLP) techniques to extract meaningful insights about the sentiment and emotions expressed by users. Given the limitations of paid APIs, I opted to use Selenium for web scraping, as it is a free and robust tool for collecting real-time tweets. Specifically, I collected 20 tweets related to Gaza for the sentiment analysis task.\n",
    "\n",
    "After successfully scraping the tweets, the next step involved cleaning the data to ensure it was suitable for sentiment analysis. This was achieved by removing unwanted elements such as URLs, mentions, hashtags, and special characters, converting text to lowercase, removing stop words, and applying stemming techniques. Additionally, I implemented a separate cleaning function tailored for Arabic tweets to handle multilingual data.\n",
    "\n",
    "Once the tweets were cleaned, they were stored in a CSV file for easy reuse in future analyses or related tasks. For sentiment analysis, I integrated the GroqCloud platform's Llama-3 model, a powerful large language model (LLM), to perform in-depth sentiment evaluation. This model was used to gain a deeper understanding of the emotional content of the tweets. Following the analysis, I posed a question to the LLM: \"Based on the tweets, how do the people of Gaza feel right now?\"\n",
    "\n",
    "The LLM's response highlighted a complex sentiment landscape. The prevailing emotions among the people of Gaza and those concerned about the situation included fear, anger, and frustration due to the ongoing conflict. However, the analysis also revealed a sense of resilience, solidarity, and hope. The tweets frequently expressed a desire for peace, accountability for human rights violations, and a resolution to the conflict that honors the dignity and rights of all involved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
